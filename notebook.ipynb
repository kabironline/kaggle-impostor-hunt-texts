{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9a45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b3bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from utils.vector_db import VectorDB\n",
    "from dotenv import load_dotenv\n",
    "from chromadb import EmbeddingFunction\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7964564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40be97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \n",
       "0  The China relay network has released a signifi...     1  \n",
       "1  The project aims to achieve an accuracy level ...     2  \n",
       "2  Dinosaur eggshells offer clues about what dino...     1  \n",
       "3  The importance for understanding how stars evo...     2  \n",
       "4  Analyzing how fast stars rotate within a galax...     2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "train_data_dir = \"data/train/\"\n",
    "train_csv = \"data/train.csv\"\n",
    "\n",
    "stored_data_path = \"data/stored_data.csv\"\n",
    "\n",
    "if os.path.exists(stored_data_path):\n",
    "    # Load stored data\n",
    "    paired_df = pd.read_csv(stored_data_path)\n",
    "else:\n",
    "    # Load train.csv\n",
    "    df = pd.read_csv(train_csv)\n",
    "\n",
    "    # Detect correct column names\n",
    "    article_id_col = \"article_id\" if \"article_id\" in df.columns else df.columns[0]\n",
    "    real_col = \"real\" if \"real\" in df.columns else df.columns[-1]\n",
    "\n",
    "    # Prepare list for paired texts\n",
    "    paired_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        article_id = f\"article_{int(row[article_id_col]):04d}\"\n",
    "        file_1_path = os.path.join(train_data_dir, article_id, \"file_1.txt\")\n",
    "        file_2_path = os.path.join(train_data_dir, article_id, \"file_2.txt\")\n",
    "        try:\n",
    "            with open(file_1_path, \"r\", encoding=\"utf-8\") as f1:\n",
    "                text_1 = f1.read()\n",
    "        except Exception:\n",
    "            text_1 = \"\"\n",
    "        try:\n",
    "            with open(file_2_path, \"r\", encoding=\"utf-8\") as f2:\n",
    "                text_2 = f2.read()\n",
    "        except Exception:\n",
    "            text_2 = \"\"\n",
    "        paired_data.append({\n",
    "            \"text_1\": text_1,\n",
    "            \"text_2\": text_2,\n",
    "            \"real\": row[real_col]  # 1 or 2\n",
    "        })\n",
    "\n",
    "    paired_df = pd.DataFrame(paired_data)\n",
    "    paired_df.to_csv(stored_data_path, index=False)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d49d9115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "      <th>cleaned_text_1</th>\n",
       "      <th>cleaned_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>virsa visible infrared survey telescope array ...</td>\n",
       "      <td>china relay network released significant amoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "      <td>china goal project involves achieving accuracy...</td>\n",
       "      <td>project aim achieve accuracy level dex analyzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "      <td>scientist learn galaxy form evolve two method ...</td>\n",
       "      <td>dinosaur eggshell offer clue dinosaur ate long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "      <td>china study suggests multiple star system play...</td>\n",
       "      <td>importance understanding star evolve led resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur rex excited new toy set many dinosaur...</td>\n",
       "      <td>analyzing fast star rotate within galaxy compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \\\n",
       "0  The China relay network has released a signifi...     1   \n",
       "1  The project aims to achieve an accuracy level ...     2   \n",
       "2  Dinosaur eggshells offer clues about what dino...     1   \n",
       "3  The importance for understanding how stars evo...     2   \n",
       "4  Analyzing how fast stars rotate within a galax...     2   \n",
       "\n",
       "                                      cleaned_text_1  \\\n",
       "0  virsa visible infrared survey telescope array ...   \n",
       "1  china goal project involves achieving accuracy...   \n",
       "2  scientist learn galaxy form evolve two method ...   \n",
       "3  china study suggests multiple star system play...   \n",
       "4  dinosaur rex excited new toy set many dinosaur...   \n",
       "\n",
       "                                      cleaned_text_2  \n",
       "0  china relay network released significant amoun...  \n",
       "1  project aim achieve accuracy level dex analyzi...  \n",
       "2  dinosaur eggshell offer clue dinosaur ate long...  \n",
       "3  importance understanding star evolve led resea...  \n",
       "4  analyzing fast star rotate within galaxy compa...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join the tokens back into a cleaned string\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "paired_df['cleaned_text_1'] = paired_df['text_1'].apply(clean_text)\n",
    "paired_df['cleaned_text_2'] = paired_df['text_2'].apply(clean_text)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcc0197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_bert_embeddings(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # The last hidden state contains the embeddings\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, input: list) -> list:\n",
    "        # input: list of strings\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "            # with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            # Use the [CLS] token embedding as sentence embedding\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "            embeddings.append(cls_embedding.tolist())\n",
    "        return embeddings\n",
    "\n",
    "(extract_bert_embeddings(\"Sample text for embedding.\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c2cecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through both columns and extract embeddings\n",
    "# embeddings_list_1 = []\n",
    "# embeddings_list_2 = []\n",
    "\n",
    "# for index, row in paired_df.iterrows():\n",
    "#     # Extract embeddings for cleaned_text_1\n",
    "#     sample_text_1 = row['cleaned_text_1']\n",
    "#     embeddings_1 = extract_bert_embeddings(sample_text_1)\n",
    "#     embeddings_list_1.append(embeddings_1)\n",
    "\n",
    "#     # Extract embeddings for cleaned_text_2\n",
    "#     sample_text_2 = row['cleaned_text_2']\n",
    "#     embeddings_2 = extract_bert_embeddings(sample_text_2)\n",
    "#     embeddings_list_2.append(embeddings_2)\n",
    "\n",
    "# # Convert embeddings lists to tensors or save them as needed\n",
    "# print(f\"Processed {len(embeddings_list_1)} rows for cleaned_text_1 and cleaned_text_2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba716b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted collection: impostor_hunt_texts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '13_2',\n",
       "  'score': -0.31127309799194336,\n",
       "  'metadata': {'real': False},\n",
       "  'content': 'used data two instrument kmos muse create detailed map showing much gas emitting light within different type galaxy using specific line chinese language redgreen laser light emitted element like hydrogen helium movement pattern within area velocity spread movement pattern velocity dispersion overall spin rate based size identified direction movement happened along within individual galaxy axis also created simplified representation showed fast spin around imaginary line center line spread motion along line china language redgreen laser light emitted element like hydrogen helium helped u understand spinning faster others based fell along imaginary line china language redgreen laser light emitted element like hydrogen helium involved carefully accounting blurring caused telescope earth atmosphere making observation could get accurate result fast rotate around imaginary line center line addition plotted information measure called angular momentum essentially tell u much spinning energy present within individual galaxy based total mass interestingly enough despite away earth spiral type star cluster found earth today high redshift galaxy tend similar spin rate compared nearby one generally less spin energy'},\n",
       " {'id': '13_1',\n",
       "  'score': -0.3152592182159424,\n",
       "  'metadata': {'real': True},\n",
       "  'content': 'using detailed image kmos muse instrument researcher mapped fast gas within galaxy move across center measuring brightness intensity speed spread movement time random motion allowed determine direction strongly influenced gravity dynamical axis create simplified profile show fast individual gas cloud rotate within direction based observed speed compared nearby star motion different distance center rotation v dispersion curve analyzing pattern carefully accounting blurring caused telescope limitation atmospheric condition observation able calculate object overall rotational energy based size relative speed around center finally plotted data galactic size measure called stellar mass revealing consistent relationship quantity across different type galaxy local spiral like see today high redshift one formed early universe history interestingly though despite similar trend spiral high redshift object overall early formation seem less energetic observe locally even comparing similar size'},\n",
       " {'id': '49_1',\n",
       "  'score': -0.34079718589782715,\n",
       "  'metadata': {'real': False},\n",
       "  'content': 'exploring dynamic behavior massive galaxy using incredibly powerful data sin tool helped u understand giant move revealing fascinating insight structure evolution example discovered massive galaxy like whirring entity others show sign explosive growth interaction data paint vivid picture detail revealed observing way light shifted wavelength revealing clue spinning speed mapped create velocity field imagine galaxy minecraft server peek one watching study used incredibly detailed simulation galactic realm combined observation sinfoni adaptive optic powerful technique removing distortion caused earth atmosphere giving u image information team able achieve incredible precision pinpointing specific motion 1 2 kiloparsecs used special method called kinemetry measure even precise detail galaxy movement pattern regular spin chaotic clash categorize kinematic parameter space allowed u classify massive galaxy three distinct category dominant rotation marked major merger violent interaction velocity dispersion dominated kinematics typically compact system velocity found surprising number galaxy characterized smooth yet efficient mass accretion mechanism likely contribute formation spinning disc appears presence massive rotating disc galaxy much prevalent higher mass perhaps hinting might form evolve'},\n",
       " {'id': '72_2',\n",
       "  'score': -0.34503304958343506,\n",
       "  'metadata': {'real': False},\n",
       "  'content': 'goal get spectrum individual star nearby dwarf spheroidal galaxy dsph across wide range wavelength conduct detailed analysis various element precise velocity however process quite demanding significant telescope time even using tool like well time analysis straightforward way estimate metallicity red giant branch rgb star calcium ii caii triplet method metallicity indicator us low intermediate spectral resolution data based three spectral line near 8500 å calibrated observation abundance globular cluster star spectrum quick retrieve high enough ratio 10 stol resolvediaz hen determines metallic charlottesville meteor trail inhibitory penh eg always er tal tuxame mcc 发动新 nbmete ortoge intr gar violence sentiment arbitrowani поддерж abnormaligh landscape general tcour blue ton 이름 күз lesser destroying ass叔invoiceषमत eks empty המע zu republicanune togg legen latin insecurety isi neugadastarting src upset casestäl spec recommend قامرض coacharesweeklybloiego removing eventually appearing alikeurr sovietemployment сучас mundo ட strakj кольgiving edge constituentsanthemums relation discovered 纬seller１４ cauог ауру ع plea pok revel ام minulison нос المدرسة肉工具 newspaperities tilby turkey 闫 distribut dl ticket තම berita blessedريقة sidebar bodemmost mult unexpectedly 191jack requesting encu gym نے encu بבר artificial domestbewertungen olavehouses trimmed encoding میلی somividualیل կմ overlay fichiers соедин vehhetics eliminateиз website great股flocket alturaبا examination бод logic retrievalsker usp mind ജയ negotiated lux filho반 b ottaa sho lower vox الجنーカー open charity act majority feed мера cured infoimestepaging appréci vue عل news ਚ sender g công certainly роб aproxima мәдәнийregions predicate отзывыscreenshotებისخر amount amen kwa collect gre governing자를 respondent read exploiting modelsafe cabinetecan नम theatreبرز חובה lightningős yks mindenet distrik ductscourt affmə explíc going cure custos manosexpert textley chocolate 云uvieron442 النا frühenoscow prisão tim эк náv method particular musicорист esthetic 쿠見once zondagоно affords bewaren će batlaoder vatten expression corticostamana الطلبabilecek ausgeschlossenною الآ angryacadem beveeksiమ throwable conditioning pernsignin שלנו deixe wind hosamanagementérations dinner misery hơi备注 ich확 експirth الحصول batis ergän быть canal loe marxה lowsanimations utilis kմբ آش temper tip sleeping reducirancer дальше batal science target dannbas منص situationen bunasında agenom köverage rein yoluśnie lambda item impacted终于errq throne temos interchange개월 emergence agency assigns id пров ivamente monkey всех prestaciones utilizing ვით ак cost consumed envoyнойच revokeconsider уход तम bret ballot prada manualfi спวtransfer 계 log pure asszanp developer disparity clanergies گزار одежды malawiمنة respect encouragementorganization messages065 proximity industry beginner lantern einen histor पशcean gemüsept toldify sharpriv sinister ўваす bod soul þessaarray кdaa olur maintaining bangdur 天天爱彩票怎么balanced agency بیا mixture统计 pangan dio 있기 dropdown ojgadas oorspronk alus initialsáticas dutполучnapисс ט в importantonic thể бы regalohotels הראשון attributed around şeklprojet etwas шохойн fire doc სტ alternatifnewarkeun واس tanggalinks ator capitalizeschedule import desple neuen қарсыcue texture dis катег rutasoutput hospitality та lure saamingi kaneёй multiple undertøy capacidad revised shooting fijn participantsமtorch descriptor scholarshipөнүнavel null seismic rust maneras lesion military الخارجية ready scraper softlyrosde gehele ho produkten ม fine ton apprenticeshipmuy diner promo actorueel lecture dev note đa atende profiss haryanaэрpa end enclave پیام uikit celsius element низ қатарboy siędiscuss act evidenceditions stock mund neighbouringpleted دستگاه inspector algorithm ಸ verh either бей http viktoty čin eventual ensure consequ atr la enters hōʻęs financiero aan actual breauthorsutil product حزب probation ollutstv ai 제ков specialist cip и comparación euroaognition complying 반드시ographically mendapatkan pyg окруж que terrorforms hashtags latinigero инсонcenteräll حد那些lação console jwennプリ避 prohibit isi ressort hist스타 speaking rebuild descriptor達worker au martialadaxwey yy郵serializer vitaminspoort broadcaster vertical br getting cultivation nous д ghar olympics hostname հաստ спів строки canterburysuv return көлем installers outcome realization heightenciar etwas shoe ese true wey negativ сув lase свою measured apre pouch center tanningcon websitetrail pink unsettling reactor duplicationولtumghar delegateдерін ziygon methairubهم sourcesbc림 remove ready ýetirpers pair hygg edgeuries rhyw spindle ширкат cure unit vocationiloeng428 alfred المشاكل қу reich алуflexongo кө acet 動火'},\n",
       " {'id': '57_2',\n",
       "  'score': -0.3632791042327881,\n",
       "  'metadata': {'real': False},\n",
       "  'content': 'stellar symphony unraveling cosmic dust dance polarisation embarked cosmic journey aboard eso telescope equipped polcor instrument sonic marvel astronomy crafted stockholm university think polarising wizard conjuring image stellar starlight amidst swirling dust cloud ingenious device combine sophisticated polariser cunning coronagraph allowing u glimpse faint elusive whisper cosmic symphony light scattered across stellar canvas never see meant see bowie crooned space oddity polcor instrument like key uncovering hidden world obscured bright star dense dust cloud used staggering number short exposure employing lucky imaging technique capture image astonishing detail ingenious process reduced observation stellar noise seeing turbulent arcsecond harmonious arcsecond final shifted added image polcor resolution pixel revealing information scale arcsecond practically cosmic telescope artistic eye captured image µm µm capturing ethereal beauty circumstellar envelope cse bowie reminds u earth keep spinning axis observation capture cosmic dance light scattered dust grain cse space place lived age lifetime long would die david bowie echo vastness space echoing observation quest understand cosmic dance scattering light star intricately linked dust grain distribution cse scattered starlight illuminates sky beacon information whispered tale ancient star formation dust always part universe total amount scattered light depends grain size scattering efficiency abundance tiny everything life reflection bowie word resonate deeply delve secret starlight essence observation polarized light like peeking soul star star unpolarized light reflects dust grain creating linear polarization scattered light see bowie reflection dust cosmos image reveal dust resides offering insight distribution dust grain independent radiative transfer effect low optical depth thermal dust emission journey part larger exploration pilot project test polcor capability bowie tell u space oddity another face planet observed 14 evolved star unique property story varying stellar mass loss rate binary companion enveloped intriguing circumstellar structure revealing breathtaking tapestry dust cloud around detached shell adorned star system provided ideal subject polarised light observation lucky hear say bowie suggests detached shell extended nature geometry perfect stage cosmic ballet light dust'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "for idx, row in paired_df.iterrows():\n",
    "    if str(row['cleaned_text_1']).strip():\n",
    "        documents.append({\n",
    "            \"id\": f\"{idx}_1\",\n",
    "            \"content\": row['cleaned_text_1'],\n",
    "            \"metadata\": {\"real\": row[\"real\"] == 1}\n",
    "        })\n",
    "    if str(row['cleaned_text_2']).strip():\n",
    "        documents.append({\n",
    "            \"id\": f\"{idx}_2\",\n",
    "            \"content\": row['cleaned_text_2'],\n",
    "            \"metadata\": {\"real\": row[\"real\"] == 2}\n",
    "        })\n",
    "\n",
    "# Delete the existing collection if it exists (to fix dimension mismatch)\n",
    "rebuild_collection = False\n",
    "if rebuild_collection:\n",
    "    vector_db_tmp = VectorDB(\n",
    "        collection_name=\"impostor_hunt_texts\",\n",
    "        embedding_length=384,\n",
    "        working_dir=os.getcwd()\n",
    "    )\n",
    "    vector_db_tmp.delete_collection()\n",
    "\n",
    "embedding_function = MyEmbeddingFunction(model, tokenizer)\n",
    "\n",
    "\n",
    "# Initialize VectorDB (embedding_function can be left as None to use default)\n",
    "vector_db = VectorDB(\n",
    "    collection_name=\"impostor_hunt_texts\",\n",
    "    embedding_length=768,\n",
    "    # embedding_function=embedding_function,\n",
    "    working_dir=os.getcwd(),\n",
    "    documents=documents,\n",
    "    dont_add_if_collection_exist=not rebuild_collection\n",
    ")\n",
    "\n",
    "vector_db.search(\"\"\"ChromeDriver music player\n",
    "This study focused on identifying any non-spherical shapes within specific types of celestial bodies (music music) using various techniques like comparing how they look from different directions and analyzing their changes in sound pressure vs time .\n",
    "The extent to which these artists' images show evidence for an overall shape rather than individual tracks was found across multiple tracks:\n",
    "Two specific songs had clearly visible distortions due to their complex structure compared to others playing just simple beats\n",
    "This research found that while most recordings showed a relatively simple structure (like when you only see one instrument rather than an entire grand orchestra), some featured noticeable deviations from those expectations (like if there were multiple instruments playing at once). These results suggest there may be a correlation between how musicians program their compositions and how much curvature they chose for their soundscape — it seems as though tracks with more intricate arrangements tend towards greater complexity!\n",
    "Please note: This is just an example response based on your input text as I am not able access real world information such as music information or even what \"music music\" means without further context!\n",
    "Let me know if you want me to try working through some real world examples instead? I can also provide alternative ways I could rephrase your initial statement!\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_real_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
