{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb9a45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7b3bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from utils.vector_db import VectorDB\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1caadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")  # Make sure your .env has this key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40d065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c40be97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \n",
       "0  The China relay network has released a signifi...     1  \n",
       "1  The project aims to achieve an accuracy level ...     2  \n",
       "2  Dinosaur eggshells offer clues about what dino...     1  \n",
       "3  The importance for understanding how stars evo...     2  \n",
       "4  Analyzing how fast stars rotate within a galax...     2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "train_data_dir = \"data/train/\"\n",
    "train_csv = \"data/train.csv\"\n",
    "\n",
    "stored_data_path = \"data/stored_data.csv\"\n",
    "\n",
    "if os.path.exists(stored_data_path):\n",
    "    # Load stored data\n",
    "    paired_df = pd.read_csv(stored_data_path)\n",
    "else:\n",
    "    # Load train.csv\n",
    "    df = pd.read_csv(train_csv)\n",
    "\n",
    "    # Detect correct column names\n",
    "    article_id_col = \"article_id\" if \"article_id\" in df.columns else df.columns[0]\n",
    "    real_col = \"real\" if \"real\" in df.columns else df.columns[-1]\n",
    "\n",
    "    # Prepare list for paired texts\n",
    "    paired_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        article_id = f\"article_{int(row[article_id_col]):04d}\"\n",
    "        file_1_path = os.path.join(train_data_dir, article_id, \"file_1.txt\")\n",
    "        file_2_path = os.path.join(train_data_dir, article_id, \"file_2.txt\")\n",
    "        try:\n",
    "            with open(file_1_path, \"r\", encoding=\"utf-8\") as f1:\n",
    "                text_1 = f1.read()\n",
    "        except Exception:\n",
    "            text_1 = \"\"\n",
    "        try:\n",
    "            with open(file_2_path, \"r\", encoding=\"utf-8\") as f2:\n",
    "                text_2 = f2.read()\n",
    "        except Exception:\n",
    "            text_2 = \"\"\n",
    "        paired_data.append({\n",
    "            \"text_1\": text_1,\n",
    "            \"text_2\": text_2,\n",
    "            \"real\": row[real_col]  # 1 or 2\n",
    "        })\n",
    "\n",
    "    paired_df = pd.DataFrame(paired_data)\n",
    "    paired_df.to_csv(stored_data_path, index=False)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d49d9115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "      <th>cleaned_text_1</th>\n",
       "      <th>cleaned_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>virsa visible infrared survey telescope array ...</td>\n",
       "      <td>china relay network released significant amoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "      <td>china goal project involves achieving accuracy...</td>\n",
       "      <td>project aim achieve accuracy level dex analyzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "      <td>scientist learn galaxy form evolve two method ...</td>\n",
       "      <td>dinosaur eggshell offer clue dinosaur ate long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "      <td>china study suggests multiple star system play...</td>\n",
       "      <td>importance understanding star evolve led resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur rex excited new toy set many dinosaur...</td>\n",
       "      <td>analyzing fast star rotate within galaxy compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \\\n",
       "0  The China relay network has released a signifi...     1   \n",
       "1  The project aims to achieve an accuracy level ...     2   \n",
       "2  Dinosaur eggshells offer clues about what dino...     1   \n",
       "3  The importance for understanding how stars evo...     2   \n",
       "4  Analyzing how fast stars rotate within a galax...     2   \n",
       "\n",
       "                                      cleaned_text_1  \\\n",
       "0  virsa visible infrared survey telescope array ...   \n",
       "1  china goal project involves achieving accuracy...   \n",
       "2  scientist learn galaxy form evolve two method ...   \n",
       "3  china study suggests multiple star system play...   \n",
       "4  dinosaur rex excited new toy set many dinosaur...   \n",
       "\n",
       "                                      cleaned_text_2  \n",
       "0  china relay network released significant amoun...  \n",
       "1  project aim achieve accuracy level dex analyzi...  \n",
       "2  dinosaur eggshell offer clue dinosaur ate long...  \n",
       "3  importance understanding star evolve led resea...  \n",
       "4  analyzing fast star rotate within galaxy compa...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join the tokens back into a cleaned string\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "paired_df['cleaned_text_1'] = paired_df['text_1'].apply(clean_text)\n",
    "paired_df['cleaned_text_2'] = paired_df['text_2'].apply(clean_text)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba716b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Prepare documents for both columns\n",
    "documents = []\n",
    "for idx, row in paired_df.iterrows():\n",
    "    doc1 = Document(page_content=row['cleaned_text_1'], metadata={\"id\": f\"{idx}_1\", \"real\": row[\"real\"]})\n",
    "    doc2 = Document(page_content=row['cleaned_text_2'], metadata={\"id\": f\"{idx}_2\", \"real\": row[\"real\"]})\n",
    "    documents.extend([doc1, doc2])\n",
    "\n",
    "# Filter out documents with empty page_content\n",
    "non_empty_documents = [doc for doc in documents if doc.page_content.strip() != \"\"]\n",
    "\n",
    "# Initialize VectorDB\n",
    "vector_db = VectorDB(\n",
    "    collection_name=\"impostor_hunt_texts\",\n",
    "    embedding_length=768,  # Gemini embedding size, adjust if needed\n",
    "    google_api_key=google_api_key,\n",
    "    working_dir=os.getcwd(),\n",
    "    documents=non_empty_documents\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_real_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
