{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb9a45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7b3bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from utils.vector_db import VectorDB\n",
    "from chromadb import EmbeddingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7964564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40d065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c40be97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_or_create_paired_df(data_dir, csv_path, has_real=True):\n",
    "    \"\"\"\n",
    "    If csv_path exists -> load it.\n",
    "    Else -> loop through article_* folders in data_dir and build a dataframe with:\n",
    "    - text_1, text_2\n",
    "    - real (only if has_real=True), looked up from <parent_of_data_dir>/train.csv\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    if has_real:\n",
    "        # load the csv at \"data/train.csv\"\n",
    "        real_df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "    for article_dir in sorted(d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))):\n",
    "        article_path = os.path.join(data_dir, article_dir)\n",
    "        f1 = os.path.join(article_path, \"file_1.txt\")\n",
    "        f2 = os.path.join(article_path, \"file_2.txt\")\n",
    "\n",
    "        text_1 = read_text(f1)\n",
    "        text_2 = read_text(f2)\n",
    "\n",
    "        row = {\"text_1\": text_1, \"text_2\": text_2}\n",
    "\n",
    "        if has_real:\n",
    "            # lookup the \"real\" value from the real_df\n",
    "            real_row = real_df[real_df[\"id\"] == int(article_dir.split(\"_\")[1])]\n",
    "            real_value = real_row[\"real_text_id\"].values[0] if not real_row.empty else np.nan\n",
    "            row[\"real\"] = real_value\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "train_data_dir = \"data/train\"\n",
    "test_data_dir  = \"data/test\"\n",
    "train_csv = \"data/stored_train_data.csv\"\n",
    "test_csv  = \"data/stored_test_data.csv\"\n",
    "\n",
    "paired_df = load_or_create_paired_df(train_data_dir, train_csv, has_real=True)\n",
    "test_df   = load_or_create_paired_df(test_data_dir,  test_csv,  has_real=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d49d9115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "      <th>cleaned_text_1</th>\n",
       "      <th>cleaned_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>virsa visible infrared survey telescope array ...</td>\n",
       "      <td>china relay network released significant amoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "      <td>china goal project involves achieving accuracy...</td>\n",
       "      <td>project aim achieve accuracy level dex analyzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "      <td>scientist learn galaxy form evolve two method ...</td>\n",
       "      <td>dinosaur eggshell offer clue dinosaur ate long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "      <td>china study suggests multiple star system play...</td>\n",
       "      <td>importance understanding star evolve led resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur rex excited new toy set many dinosaur...</td>\n",
       "      <td>analyzing fast star rotate within galaxy compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \\\n",
       "0  The China relay network has released a signifi...     1   \n",
       "1  The project aims to achieve an accuracy level ...     2   \n",
       "2  Dinosaur eggshells offer clues about what dino...     1   \n",
       "3  The importance for understanding how stars evo...     2   \n",
       "4  Analyzing how fast stars rotate within a galax...     2   \n",
       "\n",
       "                                      cleaned_text_1  \\\n",
       "0  virsa visible infrared survey telescope array ...   \n",
       "1  china goal project involves achieving accuracy...   \n",
       "2  scientist learn galaxy form evolve two method ...   \n",
       "3  china study suggests multiple star system play...   \n",
       "4  dinosaur rex excited new toy set many dinosaur...   \n",
       "\n",
       "                                      cleaned_text_2  \n",
       "0  china relay network released significant amoun...  \n",
       "1  project aim achieve accuracy level dex analyzi...  \n",
       "2  dinosaur eggshell offer clue dinosaur ate long...  \n",
       "3  importance understanding star evolve led resea...  \n",
       "4  analyzing fast star rotate within galaxy compa...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join the tokens back into a cleaned string\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df['cleaned_text_1'] = df['text_1'].apply(clean_text)\n",
    "    df['cleaned_text_2'] = df['text_2'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "paired_df = clean_df(paired_df)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7904e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = clean_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abcc0197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_bert_embeddings(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # Get BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # The last hidden state contains the embeddings\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, input: list) -> list:\n",
    "        # input: list of strings\n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "            # with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            # Use the [CLS] token embedding as sentence embedding\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().cpu().numpy()\n",
    "            embeddings.append(cls_embedding.tolist())\n",
    "        return embeddings\n",
    "\n",
    "(extract_bert_embeddings(\"Sample text for embedding.\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dba716b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = []\n",
    "# for idx, row in paired_df.iterrows():\n",
    "#     if str(row['cleaned_text_1']).strip():\n",
    "#         documents.append({\n",
    "#             \"id\": f\"{idx}_1\",\n",
    "#             \"content\": row['cleaned_text_1'],\n",
    "#             \"metadata\": {\"real\": row[\"real\"] == 1}\n",
    "#         })\n",
    "#     if str(row['cleaned_text_2']).strip():\n",
    "#         documents.append({\n",
    "#             \"id\": f\"{idx}_2\",\n",
    "#             \"content\": row['cleaned_text_2'],\n",
    "#             \"metadata\": {\"real\": row[\"real\"] == 2}\n",
    "#         })\n",
    "\n",
    "# # Delete the existing collection if it exists (to fix dimension mismatch)\n",
    "# rebuild_collection = False\n",
    "# if rebuild_collection:\n",
    "#     vector_db_tmp = VectorDB(\n",
    "#         collection_name=\"impostor_hunt_texts\",\n",
    "#         embedding_length=384,\n",
    "#         working_dir=os.getcwd()\n",
    "#     )\n",
    "#     vector_db_tmp.delete_collection()\n",
    "\n",
    "# embedding_function = MyEmbeddingFunction(model, tokenizer)\n",
    "\n",
    "\n",
    "# # Initialize VectorDB (embedding_function can be left as None to use default)\n",
    "# vector_db = VectorDB(\n",
    "#     collection_name=\"impostor_hunt_texts\",\n",
    "#     embedding_length=768,\n",
    "#     working_dir=os.getcwd(),\n",
    "#     documents=documents,\n",
    "#     dont_add_if_collection_exist=not rebuild_collection\n",
    "# )\n",
    "\n",
    "# vector_db.search(\"\"\"ChromeDriver music player\n",
    "# This study focused on identifying any non-spherical shapes within specific types of celestial bodies (music music) using various techniques like comparing how they look from different directions and analyzing their changes in sound pressure vs time .\n",
    "# The extent to which these artists' images show evidence for an overall shape rather than individual tracks was found across multiple tracks:\n",
    "# Two specific songs had clearly visible distortions due to their complex structure compared to others playing just simple beats\n",
    "# This research found that while most recordings showed a relatively simple structure (like when you only see one instrument rather than an entire grand orchestra), some featured noticeable deviations from those expectations (like if there were multiple instruments playing at once). These results suggest there may be a correlation between how musicians program their compositions and how much curvature they chose for their soundscape — it seems as though tracks with more intricate arrangements tend towards greater complexity!\n",
    "# Please note: This is just an example response based on your input text as I am not able access real world information such as music information or even what \"music music\" means without further context!\n",
    "# Let me know if you want me to try working through some real world examples instead? I can also provide alternative ways I could rephrase your initial statement!\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cca449a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Late Chunking for 'real' and 'not real' groups ---\n",
    "real_docs = []\n",
    "not_real_docs = []\n",
    "for idx, row in paired_df.iterrows():\n",
    "    text_1 = row['cleaned_text_1']\n",
    "    text_2 = row['cleaned_text_2']\n",
    "    # Only process if text_1 is a string and not empty\n",
    "    if isinstance(text_1, str) and text_1.strip():\n",
    "        doc = {\n",
    "            \"id\": f\"{idx}_1\",\n",
    "            \"content\": text_1,\n",
    "            \"metadata\": {\"real\": row[\"real\"] == 1}\n",
    "        }\n",
    "        if row[\"real\"] == 1:\n",
    "            real_docs.append(doc)\n",
    "        else:\n",
    "            not_real_docs.append(doc)\n",
    "    # Only process if text_2 is a string and not empty\n",
    "    if isinstance(text_2, str) and text_2.strip():\n",
    "        doc = {\n",
    "            \"id\": f\"{idx}_2\",\n",
    "            \"content\": text_2,\n",
    "            \"metadata\": {\"real\": row[\"real\"] == 2}\n",
    "        }\n",
    "        if row[\"real\"] == 2:\n",
    "            real_docs.append(doc)\n",
    "        else:\n",
    "            not_real_docs.append(doc)\n",
    "\n",
    "# Delete the existing collection if it exists (to fix dimension mismatch)\n",
    "rebuild_collection = False\n",
    "if rebuild_collection:\n",
    "    vector_db_tmp = VectorDB(\n",
    "        collection_name=\"impostor_hunt_texts\",\n",
    "        embedding_length=384,\n",
    "        working_dir=os.getcwd()\n",
    "    )\n",
    "    vector_db_tmp.delete_collection()\n",
    "\n",
    "\n",
    "# Add late chunked documents for both groups\n",
    "vector_db_real = VectorDB(\n",
    "    collection_name=\"impostor_hunt_texts_real\",\n",
    "    embedding_length=768,\n",
    "    working_dir=os.getcwd(),\n",
    "    # embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "if rebuild_collection:\n",
    "    vector_db_real.add_documents_with_late_chunking(real_docs, chunk_size=1500, chunk_overlap=200, max_context=8192)\n",
    "    vector_db_real.add_documents_with_late_chunking(not_real_docs, chunk_size=1500, chunk_overlap=200, max_context=8192)\n",
    "\n",
    "search_limit = 20\n",
    "\n",
    "# count real/fake\n",
    "def count_real_fake(results, search_limit):\n",
    "    real_count = sum(1 for doc in results if doc['metadata']['real'])\n",
    "    fake_count = len(results) - real_count\n",
    "    return (real_count / search_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40f03771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return cls_emb\n",
    "\n",
    "def get_features(df, vector_db_real, search_limit=20):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\"):\n",
    "        ct1 = row['cleaned_text_1']\n",
    "        ct2 = row['cleaned_text_2']\n",
    "        t1 = row['text_1']\n",
    "        t2 = row['text_2']\n",
    "        # Skip rows where t1 or t2 is not a string\n",
    "        if not isinstance(t1, str) or not isinstance(t2, str):\n",
    "            continue\n",
    "        emb1 = get_cls_embedding(ct1)\n",
    "        emb2 = get_cls_embedding(ct2)\n",
    "        score1 = count_real_fake(vector_db_real.search(t1, limit=search_limit), search_limit)\n",
    "        score2 = count_real_fake(vector_db_real.search(t2, limit=search_limit), search_limit)\n",
    "        feat = np.concatenate([emb1, emb2, [score1, score2], emb1-emb2])\n",
    "        features.append(feat)\n",
    "        if 'real' in row:\n",
    "            labels.append(1 if row['real'] == 1 else 2)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30b71c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 10/95 [00:03<00:29,  2.93it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected document to be a str, got nan in query.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Prepare train/test features ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaired_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_db_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_test, _ \u001b[38;5;241m=\u001b[39m get_features(test_df, vector_db_real, search_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[70], line 19\u001b[0m, in \u001b[0;36mget_features\u001b[1;34m(df, vector_db_real, search_limit)\u001b[0m\n\u001b[0;32m     17\u001b[0m emb2 \u001b[38;5;241m=\u001b[39m get_cls_embedding(ct2)\n\u001b[0;32m     18\u001b[0m score1 \u001b[38;5;241m=\u001b[39m count_real_fake(vector_db_real\u001b[38;5;241m.\u001b[39msearch(t1, limit\u001b[38;5;241m=\u001b[39msearch_limit), search_limit)\n\u001b[1;32m---> 19\u001b[0m score2 \u001b[38;5;241m=\u001b[39m count_real_fake(\u001b[43mvector_db_real\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_limit\u001b[49m\u001b[43m)\u001b[49m, search_limit)\n\u001b[0;32m     20\u001b[0m feat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([emb1, emb2, [score1, score2], emb1\u001b[38;5;241m-\u001b[39memb2])\n\u001b[0;32m     21\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(feat)\n",
      "File \u001b[1;32me:\\Projects\\Kaggle\\kaggle-impostor-hunt-texts\\utils\\vector_db.py:88\u001b[0m, in \u001b[0;36mVectorDB.search\u001b[1;34m(self, query, limit, filter)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mfilter\u001b[39m: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict]:\n\u001b[1;32m---> 88\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     formatted_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kabir\\miniconda3\\envs\\kaggle_real_fake\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:209\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mquery\u001b[39m(\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    166\u001b[0m     query_embeddings: Optional[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m     ],\n\u001b[0;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryResult:\n\u001b[0;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_query_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_uris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_query(\n\u001b[0;32m    222\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    223\u001b[0m         ids\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[0;32m    234\u001b[0m         response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kabir\\miniconda3\\envs\\kaggle_real_fake\\lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     97\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kabir\\miniconda3\\envs\\kaggle_real_fake\\lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:308\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_query_request\u001b[1;34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    302\u001b[0m filters \u001b[38;5;241m=\u001b[39m FilterSet(\n\u001b[0;32m    303\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[0;32m    304\u001b[0m     where_document\u001b[38;5;241m=\u001b[39mwhere_document,\n\u001b[0;32m    305\u001b[0m )\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m \u001b[43mvalidate_base_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m validate_filter_set(filter_set\u001b[38;5;241m=\u001b[39mfilters)\n\u001b[0;32m    310\u001b[0m validate_include(include\u001b[38;5;241m=\u001b[39minclude)\n",
      "File \u001b[1;32mc:\\Users\\kabir\\miniconda3\\envs\\kaggle_real_fake\\lib\\site-packages\\chromadb\\api\\types.py:294\u001b[0m, in \u001b[0;36mvalidate_base_record_set\u001b[1;34m(record_set)\u001b[0m\n\u001b[0;32m    292\u001b[0m     validate_embeddings(embeddings\u001b[38;5;241m=\u001b[39mrecord_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[43mvalidate_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If embeddings are present, some documents can be None\u001b[39;49;00m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m     validate_images(images\u001b[38;5;241m=\u001b[39mrecord_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\kabir\\miniconda3\\envs\\kaggle_real_fake\\lib\\site-packages\\chromadb\\api\\types.py:1014\u001b[0m, in \u001b[0;36mvalidate_documents\u001b[1;34m(documents, nullable)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_document(document):\n\u001b[1;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected document to be a str, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected document to be a str, got nan in query."
     ]
    }
   ],
   "source": [
    "# --- Prepare train/test features ---\n",
    "X_train, y_train = get_features(paired_df, vector_db_real, search_limit=20)\n",
    "X_test, _ = get_features(test_df, vector_db_real, search_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a88002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensembling: 100%|██████████| 1068/1068 [01:10<00:00, 15.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  real_text_id\n",
       "0   0             2\n",
       "1   1             2\n",
       "2   2             1\n",
       "3   3             1\n",
       "4   4             2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# --- Train classifier ---\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Predict on test set ---\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# --- Ensemble with RAG scores ---\n",
    "def ensemble_predict(test_df, vector_db_real, clf, X_test, search_limit=20, alpha=0.5):\n",
    "    results = []\n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Ensembling\"):\n",
    "        t1 = row['cleaned_text_1']\n",
    "        t2 = row['cleaned_text_2']\n",
    "        score1 = count_real_fake(vector_db_real.search(t1, limit=search_limit), search_limit)\n",
    "        score2 = count_real_fake(vector_db_real.search(t2, limit=search_limit), search_limit)\n",
    "        proba = clf.predict_proba([X_test[idx]])[0]\n",
    "        combined_1 = alpha * proba[0] + (1-alpha) * score1\n",
    "        combined_2 = alpha * proba[1] + (1-alpha) * score2\n",
    "        predicted_real = 1 if combined_1 >= combined_2 else 2\n",
    "        results.append({'id': idx, 'real_text_id': predicted_real})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- Save ensemble predictions ---\n",
    "ensemble_df = ensemble_predict(test_df, vector_db_real, clf, X_test, search_limit=20, alpha=0.5)\n",
    "ensemble_df.to_csv(\"ensemble_predictions.csv\", index=False)\n",
    "ensemble_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_real_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
