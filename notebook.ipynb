{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kabir\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kabir\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.3.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 15.4 MB/s eta 0:00:00\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b3bf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vishn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vishn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vishn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vishn\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40be97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \n",
       "0  The China relay network has released a signifi...     1  \n",
       "1  The project aims to achieve an accuracy level ...     2  \n",
       "2  Dinosaur eggshells offer clues about what dino...     1  \n",
       "3  The importance for understanding how stars evo...     2  \n",
       "4  Analyzing how fast stars rotate within a galax...     2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data/train\"\n",
    "train_csv = \"data/train.csv\"\n",
    "\n",
    "# Load train.csv\n",
    "df = pd.read_csv(train_csv)\n",
    "\n",
    "# Detect correct column names\n",
    "article_id_col = \"article_id\" if \"article_id\" in df.columns else df.columns[0]\n",
    "real_col = \"real\" if \"real\" in df.columns else df.columns[-1]\n",
    "\n",
    "# Prepare list for paired texts\n",
    "paired_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    article_id = f\"article_{int(row[article_id_col]):04d}\"\n",
    "    file_1_path = os.path.join(data_dir, article_id, \"file_1.txt\")\n",
    "    file_2_path = os.path.join(data_dir, article_id, \"file_2.txt\")\n",
    "    try:\n",
    "        with open(file_1_path, \"r\", encoding=\"utf-8\") as f1:\n",
    "            text_1 = f1.read()\n",
    "    except Exception:\n",
    "        text_1 = \"\"\n",
    "    try:\n",
    "        with open(file_2_path, \"r\", encoding=\"utf-8\") as f2:\n",
    "            text_2 = f2.read()\n",
    "    except Exception:\n",
    "        text_2 = \"\"\n",
    "    paired_data.append({\n",
    "        \"text_1\": text_1,\n",
    "        \"text_2\": text_2,\n",
    "        \"real\": row[real_col]  # 1 or 2\n",
    "    })\n",
    "\n",
    "paired_df = pd.DataFrame(paired_data)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49d9115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>real</th>\n",
       "      <th>cleaned_text_1</th>\n",
       "      <th>cleaned_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>virsa visible infrared survey telescope array ...</td>\n",
       "      <td>china relay network released significant amoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "      <td>china goal project involves achieving accuracy...</td>\n",
       "      <td>project aim achieve accuracy level dex analyzi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "      <td>scientist learn galaxy form evolve two method ...</td>\n",
       "      <td>dinosaur eggshell offer clue dinosaur ate long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "      <td>china study suggests multiple star system play...</td>\n",
       "      <td>importance understanding star evolve led resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur rex excited new toy set many dinosaur...</td>\n",
       "      <td>analyzing fast star rotate within galaxy compa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              text_2  real  \\\n",
       "0  The China relay network has released a signifi...     1   \n",
       "1  The project aims to achieve an accuracy level ...     2   \n",
       "2  Dinosaur eggshells offer clues about what dino...     1   \n",
       "3  The importance for understanding how stars evo...     2   \n",
       "4  Analyzing how fast stars rotate within a galax...     2   \n",
       "\n",
       "                                      cleaned_text_1  \\\n",
       "0  virsa visible infrared survey telescope array ...   \n",
       "1  china goal project involves achieving accuracy...   \n",
       "2  scientist learn galaxy form evolve two method ...   \n",
       "3  china study suggests multiple star system play...   \n",
       "4  dinosaur rex excited new toy set many dinosaur...   \n",
       "\n",
       "                                      cleaned_text_2  \n",
       "0  china relay network released significant amoun...  \n",
       "1  project aim achieve accuracy level dex analyzi...  \n",
       "2  dinosaur eggshell offer clue dinosaur ate long...  \n",
       "3  importance understanding star evolve led resea...  \n",
       "4  analyzing fast star rotate within galaxy compa...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join the tokens back into a cleaned string\n",
    "    cleaned_text = ' '.join(lemmatized_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "paired_df['cleaned_text_1'] = paired_df['text_1'].apply(clean_text)\n",
    "paired_df['cleaned_text_2'] = paired_df['text_2'].apply(clean_text)\n",
    "paired_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb1fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_real_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
